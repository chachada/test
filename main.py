import os
import requests
import streamlit as st

from pinecone import Pinecone
from dotenv import load_dotenv
from utils import print_messages
from langchain_core.messages import ChatMessage
from langchain.embeddings.openai import OpenAIEmbeddings

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')
PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY')
PINECONE_ENVIRONMENT = os.environ.get('PINECONE_ENVIRONMENT')
HOST=os.environ.get('HOST')
API_KEY=os.environ.get('API_KEY')
API_KEY_PRIMARY_VAL=os.environ.get('API_KEY_PRIMARY_VAL')
REQUEST_ID=os.environ.get('REQUEST_ID')

# pineconeì— ì—°ê²°
api_key = os.environ.get('PINECONE_API_KEY')
index_name = os.environ.get('INDEX_NAME')

st.set_page_config(page_title="chatPoC", page_icon="ğŸ‘¤")
st.title("ğŸ‘¤ Lynn chatbot PoC")

if "messages" not in st.session_state:
    st.session_state["messages"] = []

# Pinecone í´ë¼ì´ì–¸íŠ¸ êµ¬ì„±
pc = Pinecone(api_key=api_key)

# Index í™•ì¸
pc.list_indexes()

print(pc.list_indexes())

index = pc.Index("canopy--document-uploader")

model_name = 'text-embedding-ada-002'

embed = OpenAIEmbeddings(
    model=model_name,
    openai_api_key=OPENAI_API_KEY
)

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY
embedding = OpenAIEmbeddings()


# ì´ì „ ëŒ€í™”ê¸°ë¡ ì¶œë ¥
print_messages()


class CompletionExecutor:
    def __init__(self, host, api_key, api_key_primary_val, request_id):
        self._host = host
        self._api_key = api_key
        self._api_key_primary_val = api_key_primary_val
        self._request_id = request_id

    def execute(self, completion_request):
        headers = {
            'X-NCP-CLOVASTUDIO-API-KEY': self._api_key,
            'X-NCP-APIGW-API-KEY': self._api_key_primary_val,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }

        responses = []
        done_received = False  # "DONE" ì‘ë‹µì´ ìˆ˜ì‹ ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í”Œë˜ê·¸

        with requests.post(self._host + '/testapp/v1/chat-completions/HCX-003',
                           headers=headers, json=completion_request, stream=True) as r:
            for line in r.iter_lines():
                if line:
                    response = line.decode("utf-8")
                    if response.startswith('data:{"message":{"role":"assistant","content":'):
                        response_text = response.split('"content":"')[-1]
                        response_text = response_text.split('"}')[0]
                        response_text = response_text.replace('\\n', ' ')  # ê°œí–‰ ë¬¸ì ì‚­ì œ
                        responses.append(response_text)
                    elif response.strip() == 'data:{"message":{"role":"assistant","content":"DONE"}}':
                        done_received = True  # "DONE" ì‘ë‹µ ìˆ˜ì‹ 

                    if done_received:
                        break  # "DONE" ì‘ë‹µì„ ë°›ì€ í›„ì—ëŠ” ë” ì´ìƒ ì‘ë‹µì„ ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ

        # ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë°›ì€ ì‘ë‹µ ë°ì´í„°ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹¨
        full_response = ''.join(responses)
        return full_response



if __name__ == '__main__':
    user_input = st.chat_input("ê¶ê¸ˆí•˜ì‹  ë‚´ìš©ì„ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”.")

    if user_input:
        st.chat_message("user").write(f"{user_input}")
        st.session_state["messages"].append(ChatMessage(role="user", content=user_input))

        question = [user_input]

        embedded_question = embedding.embed_documents(question)

        query_result = index.query(
            vector=embedded_question,
            top_k=20,
            include_values=False,
            include_metadata=True
        )
        print(query_result.matches[0])

        # ê²°ê³¼ë¥¼ ì¶œë ¥í•œë‹¤.
        for result in query_result.matches:
            id = result.id
            text = result.metadata['text']  # ë¬¸ì„œì˜ ì›ë³¸ í…ìŠ¤íŠ¸
            # title = result.metadata['title'] #ë¬¸ì„œì˜ ì œëª©
            score = result.score  # ë¬¸ì„œì˜ ìœ ì‚¬ë„
            print(id, score)
            print("\n")
            print(text)
            print('=' * 10)

        preset_text = [{"role": "system",
                        "content": " - ë‹¤ìŒ ë¬¸ì„œì—ë§Œ ê¸°ë°˜í•˜ì—¬ ì§ˆë¬¸ì— ëŒ€ë‹µí•©ë‹ˆë‹¤. - ë¬¸ì„œì—ì„œ ì•Œìˆ˜ ì—†ëŠ” ë‚´ìš©ì¸ ê²½ìš° 'ìì„¸í•œ ì‚¬í•­ì€ ë°˜ë“œì‹œ ê²¬ë³¸ì£¼íƒ ë° ê³ ê°ì„¼í„°ë¡œ í™•ì¸í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤. (ì•ˆë‚´ì‚¬í•­ì˜ ì˜¤ë¥˜ê°€ ìˆì„ ì‹œëŠ” ê´€ê³„ë²•ë ¹ì´ ìš°ì„ í•©ë‹ˆë‹¤.) ' ë¼ê³  í•©ë‹ˆë‹¤."},
                       {"role": "user",
                        "content": user_input}]

        # Pinecone ê²€ìƒ‰ ê²°ê³¼ë¥¼ preset_textì— ì¶”ê°€
        for result in query_result.matches:
            text = result.metadata['text']  # ë¬¸ì„œì˜ ì›ë³¸ í…ìŠ¤íŠ¸
            preset_text.append({"role": "system", "content": text})

        request_data = {
            'messages': preset_text,
            'topP': 0.6,
            'topK': 0,
            'maxTokens': 500,
            'temperature': 0.1,
            'repeatPenalty': 2.0,
            'stopBefore': [],
            'includeAiFilters': True,
            'seed': 0
        }

        completion_executor = CompletionExecutor(
            host='https://clovastudio.stream.ntruss.com',
            api_key=API_KEY,
            api_key_primary_val=API_KEY_PRIMARY_VAL,
            request_id=REQUEST_ID
        )

        response = completion_executor.execute(request_data)

        msg = response
        st.write(msg)
        st.chat_message("assistant").write(response)